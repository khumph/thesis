\RequirePackage[l2tabu, orthodox]{nag}
\documentclass[12pt]{article}
\usepackage{geometry}

\usepackage[normalem]{ulem}

% makes table of contents and such hyperlinks
\usepackage{hyperref}

% nicely formatted tables
\usepackage{booktabs}

% English language/hyphenation
\usepackage[english]{babel}

% > < print corectly, accented words hyphenate
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{microtype}
% \usepackage[subtle]{savetrees}

\usepackage{ctable}
\usepackage{tabu}
\usepackage{amsmath}
\usepackage{commath}
\usepackage[style=authoryear, hyperref = true]{biblatex}
\addbibresource{thesis.bib}

% \usepackage{tikz}
% \usetikzlibrary{arrows, shapes, positioning}

\usepackage[]{algorithm2e}
\RestyleAlgo{boxruled}
\setlength\belowcaptionskip{12pt}
\DeclareMathOperator*{\argmax}{argmax}

%--------------------------------------------------------------------------
%  TITLE SECTION
%--------------------------------------------------------------------------

\title{\normalfont \Large Using reinforcement learning to personalize dosing strategies in a simulated cancer trial with high dimensional data}

\author{\normalsize \sl Kyle Humphrey}

\date{\normalsize \sl \today}

\begin{document}

\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
        
        \uppercase{Using reinforcement learning to personalize dosing strategies in a simulated cancer trial with high dimensional data}
        
        \vfill
        
        by
        
        \vfill
        
        Kyle Humphrey
        
        \vfill
        
        \underline{\kern 2in}
        
        \vfill
        
        A thesis submitted to the faculty of the

        \vfill
        
        \uppercase{Mel and Enid Zuckerman College of Public Health}
        
        \vfill
        
        In partial fulfillment of the requirements
        
        \bigskip
        
        for the degree of
        
        \vfill
        
        \uppercase{Master of Science}
        
        \medskip
        
        \uppercase{With a major in Biostatistics}
        
        \vfill
        
        In the Graduate College 
        
        \vfill
        
        \uppercase{The University of Arizona}
        
        \vfill
        
        2017
        
    \end{center}
\end{titlepage}

\begin{center}
STATEMENT BY AUTHOR
\end{center}

The thesis titled ``Using reinforcement learning to personalize dosing strategies in a simulated cancer trial with high dimensional data'' prepared by Kyle Humphrey has been submitted in partial fulfillment of requirements for a master’s degree at the University of Arizona and is deposited in the University Library to be made available to borrowers under rules of the Library.  

\medskip

Brief quotations from this thesis are allowable without special permission, provided that an accurate acknowledgement of the source is made. Requests for permission for extended quotation from or reproduction of this manuscript in whole or in part may be granted by the head of the major department or the Dean of the Graduate College when in his or her judgment the proposed use of the material is in the interests of scholarship.  In all other instances, however, permission must be obtained from the author.

\bigskip
\bigskip

\begin{tabu}{XX[3, c]}
  & SIGNED: \emph{Kyle Humphrey}
\end{tabu}

\vfill

{\centering
  \uppercase{Approval by thesis director}
  
  \bigskip
  
  This thesis has been approved on the date shown below:
  
  \vspace{1cm}

\emph{
\begin{tabu} to \textwidth {X[1.3, c] X[c]}
  \underline{\kern 2.5in} & \underline{\quad April 26, 2017 \quad}\\
  Jin Zhou, Ph.D. &   \emph{Date} \\
  Assistant Professor of Biostatistics & \\[0.5cm]
  \underline{\kern 2.5in} & \underline{\quad April 26, 2017 \quad} \\
  Chengcheng Hu, Ph.D. &   \emph{Date} \\
  Associate Professor of Biostatistics & \\[0.5cm]
  \underline{\kern 2.5in} & \underline{\quad April 26, 2017 \quad} \\
  Chiu-Hsieh Hsu, Ph.D. &   \emph{Date} \\
  Associate Professor of Biostatistics &
\end{tabu}
}
}

\newpage

\begin{abstract}
In a simulation of an advanced generic cancer trial, I use Q-learning, a reinforcement learning algorithm, to develop dynamic treatment regimes for a continuous treatment, the dose of a single drug. Selected dynamic treatment regimes are tailored to time-varying patient characteristics and to patient subgroups with differential treatment effects. This approach allows estimation of optimal dynamic treatment regimes without a model of the disease process or a priori hypotheses about subgroup membership. Using observed patient characteristics and outcomes from the simulated trial, I estimate Q-functions based on 1) a single regression tree grown by the Classification And Regression Trees (CART) method, 2) random forests, and 3) a slightly modified version of Multivariate Adaptive Regression Splines (MARS). I then compare the survival times of an independent group of simulated patients under treatment regimes estimated using Q-learning with each of the three methods, 10 constant dose regimes, and the best possible treatment regime chosen using a brute force search over all possible treatment regimes with complete knowledge of disease processes and their effects on survival. I also make these comparisons in scenarios with and without spurious high dimensional covariates and with and without patient subgroups with differential treatment effects. Treatment regimes estimated using Q-learning with MARS and random forests greatly increased survival times when compared to the constant dose regimes, but were still considerably lower than the best possible dose regime. Q-learning with a single regression tree did not outperform the constant dose regimes. These results hold across high dimensional and subgroup scenarios. While the MARS method employed produces much more interpretable models than random forests, and therefore has more promise for patient subgroup identification, I show that it is also more sensitive to variations in training data.
\end{abstract}

\tableofcontents
\listoffigures
\listoftables

\section{Introduction}

\subsection{Personalized medicine} % (fold)
\label{sub:personalized_medicine}

% Why personalized medicine?}

Patients often show significant differences in their responses to treatment. Adverse reactions to drugs alone contribute to significant public health burden despite these drugs being shown to be beneficial (on average) in clinical trials (\cite{Pirmohamed2004}). Not only are there subpopulations for whom treatments are especially deleterious, some groups have a more robust response to certain treatments. Significant gains in public health can therefore be made from identifying these subgroups and the corresponding treatments which are most effective for them, rather than relying on identification of only the most effective treatment overall.

% What is personalized medicine?

This is the idea of \emph{personalized medicine}\footnote{Personalized medicine is also called precision medicine, stratified medicine, and P4 medicine}, which is the commonsensical notion that the best treatment for a given patient depends upon that patients' characteristics (\cite{pm-defn}). The term is most often used today when the patient characteristics are biomarkers, perhaps whether metastatic breast cancer cells  over-express human epidermal growth factor receptor 2 (are HER2-positive), and these biomarkers are used to determine the best treatment for a particular individual, and when to use it. In the case of the patients with HER2-positive cells, they should receive a different treatment (trastuzumab) from those with HER2-negative cells (\cite{Baselga2006}).
% When/where did personalized medicine start?
However, the general idea goes back at least as far as Hippocrates\footnote{Hippocrates is attributed with saying ``It is more important to know what sort of person has a disease than to know what sort of disease a person has.'' (\cite{Fischer2015})} and is implemented in principle whenever a physician tries to inform a treatment decision by determining whether the cause of an infection is bacterial or viral.

While personalized medicine in principle has a long history and shows considerable promise, there are numerous challenges in identifying these patient subgroups and the optimal treatment for each. Chief among them is the question of how to select from what is often a multitude of plausible subgroups. Narrowing down these subgroups is hindered by disease processes which are usually quite complicated and not well understood. Furthermore, optimal treatments can change over time with changing disease. This is especially true of chronic diseases, however little evidence is available to inform how to tailor treatments over time and using the information from previous treatments. 

% subsection personalized_medicine (end)

\subsection{Statistical methods to personalize medicine} % (fold)
\label{sub:statistical_methods_to_personalize_medicine}

% subsection statistical_methods_to_personalize_medicine (end)

\subsubsection{Traditional methods} % (fold)
\label{ssub:traditional_methods}

% traditional methods: ad hoc subgroup analyses, or searching for treatment by subgroups interactions

Statistically, the personalization of medicine involves the identification of patient subgroups which respond to treatment differently. Traditionally, this is accomplished by investigation of (often ad hoc) treatment by covariate interactions, where different values of a covariate identify subgroups (\cite{Byar1985}). Using the HER2 breast cancer example above, we would encapsulate our knowledge of a patient's HER2 status into a binary covariate which equaled one if her tumor was HER2 postitive or zero if her tumor was HER2 negative. We would then statistically test if the coefficient on an interaction term with this indicator and treatment is significantly different from zero.

% Problems: Curse of dimensionality, multiple comparisons

While straightforward, this approach has several problems. First, which subgroups to examine is often a subjective judgement made by the researcher (as is which cutoff to use to create subgroups from continuous covariates). Second, since the number of plausible subgroups can be quite large in typical problems, the number of interaction terms required must also be large. In addition to issues with multiple comparison, this requires much larger sample sizes (i.e. it suffers from the curse of dimensionality).

\subsubsection{Algorithms for detecting interactions} % (fold)
\label{ssub:algorithms_for_detecting_interactions}

%%%%%
% interaction trees - easy to interpret, final trees don't connect with any objective function - hard to determine optimal treatment for patients

% Su, X., Tsai, C.-L., Wang, H., Nickerson, D. M., and Li, B. (2009), “Subgroup analysis via recursive partitioning,” Journal of Machine Learning Research, 10, 141–158.
% introduces interaction trees - applys to wage data
%
% Lipkovich, I., Dmitrienko, A., Denne, J., and Enas, G. (2011), “Subgroup identification based on differential effect search A recursive partitioning method for establishing response to treatment in patient subpopulations,” Statistics in Medicine, 30, 2601–2621.
% method of splitting to maximize treatment effect in one daughter node relative to other
% SIDES paper - has examples of personalized medicine in intro

% STIMA, others could also be included in this group

In response to the above problems with the traditional approach, several novel algorithms to detect interactions have been developed. Many use recursive partitioning (the basic process of which is described below) with a splitting criterion based on the degree of interaction (\cite{Zeileis2008}; \cite{Su2009}; \cite{Lipkovich2011}; \cite{Dusseldorp2014}). These (and models based on recursive partitioning in general) have the advantage of being easy to interpret.

%%%%%
% two-step methods: first step: estimate differential treatment effect of each ind by score function, then use scores as response in second step - (Cai et al., 2011; Zhao et al., 2013; Foster et al., 2011; Faries et al., 2013) \\
%   need to impose parametric models that may be misspecified, hard to interpret
%
% Cai, T., Tian, L., Wong, P. H., and Wei, L. (2011), “Analysis of randomized comparative clinical trial data for personalized treatment selections,” Biostatistics, 12, 270–282.
% talks about estrogen receptive cancer cells is that what I mean?
%
% Zhao, L., Tian, L., Cai, T., Claggett, B., and Wei, L.-J. (2013), “Effectively selecting a target population for a future comparative study,” Journal of the American Statistical Association, 108, 527–539.
%
% Foster, J. C., Taylor, J. M., and Ruberg, S. J. (2011), “Subgroup identification from randomized clinical trial data,” Statistics in Medicine, 30, 2867–2880.
%
% Faries, D. E., Chen, Y., Lipkovich, I., Zagar, A., Liu, X., and Obenchain, R. L. (2013), “Local control for identifying subgroups of interest in observational research: Persistence of treatment for major depressive disorder,” International Journal of Methods in Psychiatric Research, 22, 185–194.

Other methods use a two-step process (\cite{Cai2011}; \cite{Zhao2013}; \cite{Foster2011}). The first step is to estimate the differential treatment effect of each participant and use this to develop a score to group patients. These scores are then used as a response in the second step to estimate the mean treatment difference between groups. These methods require a parametric or semi-parametric model in the first step which is subject to misspecification. 

%%%%%
% maximize value function
%
% Qian, M. and Murphy, S. A. (2011), “Performance guarantees for individualized treatment rules,” Annals of Statistics, 39, 1180.
%
% Zhao, Y., Zeng, D., Rush, A. J., and Kosorok, M. R. (2012), “Estimating individualized treatment rules using outcome weighted learning,” Journal of the American Statistical Association, 107, 1106–1118.
%
% Zhang, B., Tsiatis, A. A., Davidian, M., Zhang, M., and Laber, E. (2012), “Estimating optimal treatment regimes from a classification perspective,” Stat, 1, 103–114.

A third class of methods maximize mean responses across patients and subgroups either by using penalized regression (\cite{Qian2011}), or by treating the identification of subgroups as a classification problem with each participant weighted by their outcome (\cite{Zhao2012}; \cite{Zhang2012}).

These and other methods are promising but none address how to select the optimal value of a continuous treatment, so it is not clear how to extend them to address our goal of determining optimal dosing strategies. Perhaps more importantly, none of the methods described above directly consider more than a single stage of treatment. In practice treatments are often changed over time based off of patient response and other factors, particularly in the management of chronic disease. To truly personalize medicine, therefore, it is important to determine how to adapt treatment over time to changing situations. 

% All limited to single step?

% subsubsection novel_algorithms_for_detecting_interactions (end)

% subsubsection statistical_methods_to_personalize_medicine (end)

% How can reinforcement learning be of use in determining personalized treatments?

\subsection{Overview of paper contents} % (fold)
\label{sub:overview_of_contents}

In this paper, we will see how the obstacles to identifying optimal treatment regimes for a given individual can be addressed using Q-learning, a algorithm from reinforcement learning, in conjunction with statistical learning models. We will see how these methods can dramatically increase survival times in a simulated cancer clinical trial where doses of a single drug are chosen at each month of treatment, without a model of the disease process or a priori hypotheses about subgroup membership. The simulation was inspired by \textcite{crt} who achieved similar results using extremely randomized trees and support vector regression to estimate Q-functions. We will replicate and extend their results to more scenarios (e.g. situations with many meaningless covariates and patient subgroups), contrast their results with results obtained using more interpretable models, and compare all of the above to the best possible treatment sequence chosen with complete knowledge of disease processes and their effects on survival.

We will first briefly overview the basic elements of reinforcement learning, reinforcement learning's relevance for personalized medicine, and Q-learning (\cite{Watkins1989}) specifically. We will then discuss the supervised learning methods that I used in conjunction with Q-learning to estimate optimal dosing strategies: regression tress constructed using the classification and regression trees (CART) method (\cite{CART}), Multivariate adaptive regression splines (MARS--\cite{mars}), and random forests (RF--\cite{rf}), with random forests serving as a less interpretable comparison similar to the extremely randomized trees used by \textcite{crt}. Each technique will be illustrated with a simple example taken from the simulation. We will then discuss the details of the simulation setup and its results.

For our purposes, trees (and MARS, which shares many of their desirable properties) have several particularly appealing features. First, the tree and MARS model building procedures conduct covariate selection as part of the model building process. This will help us screen non-informative variables. Second, we need not specify the form of the relationship between the covariates and the outcome, or limit ourselves to linear or additive relationships. This will allow us to choose optimal actions without prior knowledge of disease mechanisms, which are often complicated and not well understood. Third, since single trees and MARS models are quite interpretable, we can in principle inspect them to see which variables interact with treatment and thus identify patient subgroups.

% subsection overview_of_contents (end)

\section{Reinforcement Learning} % (fold)
\label{sec:reinforcement_learning}

\subsection{Basic elements and basic process} % (fold)
\label{sub:basic_process}

Reinforcement learning is a branch of machine learning distinct from the two main branches more familiar to statisticians, supervised and unsupervised learning (\cite{Sutton2016})\footnote{Techniques from both supervised and unsupervised learning can, however, be useful in reinforcement learning problems, as we will see for supervised learning methods.}. Reinforcement learning in general is about how to make good sequences of decisions. It has the following elements:

A learning \emph{agent}, who has goals related to its \emph{environment}, loosely defined as everything outside the agent's direct control. Features of the environment are represented to the agent through \emph{states}. Given a state representation, an agent can take an \emph{action} to affect the environment in order to achieve some goal. A goal is defined to the agent in such a way that maximizing a scalar quantity called the \emph{reward} would achieve the goal. Given a state representation, an agent follows a \emph{policy}, roughly a guide to which actions to take (or which ones to favor) given a state signal. An optimal policy therefore, is a policy that achieves the largest reward over the long run.

The basic process of reinforcement learning involves a learning agent being presented with states, trying a sequence of actions, recording the consequences (rewards) of those actions in each state, estimating the relationship between the actions and their consequences, and choosing a next action that leads to the best consequences (the action that maximizes the reward, so far as the agent can tell). This is where the ``reinforcement'' in reinforcement learning comes from: actions with favorable consequences (large rewards) tend to be repeated.

% subsection basic_process (end)

\subsection{Relationship to supervised and unsupervised learning} % (fold)
\label{sub:relationship_to_supervise_and_unsupervised_learning}

Supervised learning involves a learning agent being given a list of  correct example actions to take in given situations, with the goal being that the agent then extrapolates the correct example behavior to new situations. Unsupervised learning involves finding hidden structure in collections of example actions and situations where the correct action is unknown. In reinforcement learning problems, agents do not (need to) receive direct instruction regarding which action they should take, instead they can learn which actions are best by trying them out. Further, the goal in reinforcement learning problems is to maximize a reward signal, not find hidden structure (though finding hidden structure may be useful to this end).

Also unlike other machine learning problems, reinforcement learning problems are closed-loop: the actions of the agent affect the opportunities open to the agent later on, hence consequences of actions in reinforcement learning problems can manifest not only in the next opportunity, but in all subsequent opportunities.

% subsection relationship_to_supervise_and_unsupervised_learning (end)

\subsection{Connection to personalized medicine} % (fold)
\label{sub:dynamic_treatment_regimes}

We can think of a personalized treatment as a decision rule, or a \emph{treatment regime}\footnote{Sometimes also called an individualized treatment rule} that provides the optimal action (the best treatment to give) given a patients' state (the patient's characteristics--in this context, patients are the important aspect of the environment, about whom we have goals and thus in terms of whom rewards are defined). Since for many diseases, patients often receive different stages of treatments over time, it is useful to generalize a single stage treatment regime into a \emph{dynamic treatment regime} (DTR) or in the terminology of reinforcement learning, a \emph{treatment policy}. A dynamic treatment regime generalizes of the ideas of personalized medicine by dictating treatments at each step of a sequence of possible treatment assignments based on the changing (dynamic) states of each individual patient. In order to determine which dynamic treatment regime is best (optimal) we will employ Q-learning, the most popular method for estimating optimal dynamic treatment regimes.

% subsection dynamic_treatment_regimes (end)

% section reinforcement_learning (end)

\section{Q-learning} % (fold)
\label{sec:q_learning}

Following the notation in \textcite{dtr-book}, suppose patients are recruited into a clinical trial and covariates (states) are measured before the trial begins and recorded in a vector, $O_{1}$. These covariates will be referred to as the patient history at stage 1: $H_{1} \equiv O_{1}$, which may include the baseline level of the outcome. A first treatment, $A_{1}$, is randomly assigned to each patient and each patient is measured again for the same covariates as before, the new values of which are recorded in $O_{2}$, and a reward is received, $R_{1}$. As mentioned above, this reward can be any scalar, which if maximized, would achieve the goals of the study. Most often rewards are simply set to be a continuous outcome of interest (e.g. kg of weight lost in a weight loss study). The treatment and second observation of covariates (which may include the first stage outcome and/or rewards) are incorporated into each patients' history at stage 2: $H_{2} \equiv (O_{1}, A_{1}, O_{2})$. 

A second treatment, $A_{2}$ is then assigned to each patient at random (potentially depending on $H_{2}$) and is followed by another outcome/reward, $R_{2}$. This process can be repeated through as many stages as desired. Note that this scheme can easily be modified for a single terminal outcome by setting $R_{1}, \ldots, R_{K-1} = 0$ for a sequence of $K$ stages (as we do in the simulation below). The Q-functions (Q for quality--i.e. quality of treatment decisions) are defined as the expected rewards at each stage $k$ given that treatment(s) $A_{k}$ was assigned and patient histories/characteristics up to stage $k$ were $H_{k}$:
\begin{equation}
   Q_{k}(A_{k}, H_{k})  = \operatorname{E}[r_{k} \mid A_{k}, H_{k}], \quad k = 1, \ldots, K
\end{equation}

%
% $r_{k} = (R_{1k}, R_{2k}, \ldots, R_{nk})$
%
% \begin{equation}
%   Q_{j}^{opt}(H_{j}, A_{j}; \bm{\beta}_{j}, \bm{\psi}_{j}) = \bm{\beta}^{T} H_{j0} + \bm{\psi}^{T} H_{j1} A_{j}, \quad j = 1, 2
% \end{equation}
%
% Where $H_{j0}$ are main effects of history which includes an intercept term and a main effect for treatment, $A_{j}$

\subsection{Estimating Q-functions and optimal DTRs} % (fold)
\label{sub:estimating_q_functions}

Since Q-functions are conditional expectations, standard regression techniques are applicable and hence the most popular method for estimating Q-functions in the health sciences is ordinary least squares (\cite{dtr-review}).

That being said, any modeling method can be used, and as mentioned above recently \textcite{crt} have used extremely randomized trees and support vector regression to fit Q-functions. Note that Q-functions may differ across stages of treatment. The steps of Q-learning are as follows:

\begin{enumerate}
  \item Set the Q-function after the final stage to be 0, $\hat{Q}_{K+1} \equiv 0$ (though any value will do).
  \item Create a pseudo-outcome for the last stage, $K$, by adding the rewards actually received at that stage to the estimated rewards that would have been obtained if the optimal dynamic treatment regime was followed after stage $K$:
  \begin{align}
    \hat{r}_{K} &= r_{K} + \max_{a_{K+1}} \hat{Q}_{K+1}(A_{K+1}, H_{K+1}) \\
    \hat{r}_{K} &= r_{K}
  \end{align}
  \item Estimate the preceding stage Q-function, $Q_{K - 1}$, using the pseudo-outcome just created, $\hat{r}_{K}$, as the outcome with all aspects of patient history at that stage, $H_{K}$, desired as covariates, in addition to (if fitting a linear regression model) treatment by covariate interactions for covariates in $H_{K}$ thought to be indicative of subgroups with differential treatment effects:
  \begin{equation}
      \hat{Q}_{K}(A_{K}, H_{K}) = \operatorname{E}[\hat{r}_{K} \mid A_{K}, H_{K}]
  \end{equation}
  \item Create the pseudo-outcome for the previous stage $K - 1$, again as if the optimal treatment regime will be followed after $K - 1$:
  \begin{equation}
    \hat{r}_{K-1} = r_{K-1} + \max_{a_K} \hat{Q}_{K}(A_{K}, H_{K})
  \end{equation}
  \item Repeat until you've estimated the Q-function for the first stage
\end{enumerate}

The full recursive form of Q-learning can be written as:
  \begin{equation}
     \hat{Q}_{k}(A_{k}, H_{k})  = \operatorname{E}[r_{k} + \max_{a_{k+1}} \hat{Q}_{k+1}(A_{k+1}, H_{k+1}) \mid A_{k}, H_{k}], \quad k = 1, \ldots, K
  \end{equation}

% backwards induction

% subsubsection estimating_q_functions (end)

The optimal treatment for each participant $i \in 1, \ldots, n$ at each stage $k$ is the treatment which maximizes the corresponding stage's Q-function:
\begin{equation}
  \hat{a}^{opt}_{ik} = \argmax_{a_{ik}} \hat{Q}_{k}(a_{ik}, h_{ik}), \enspace i = 1, \ldots, n; \enspace k = 1, \ldots, K
\end{equation}

Formally, Q-learning can be applied to solve any Markov decision process, and the estimated actions have been shown to converge to the optimal actions with probability one for finite Markov decision processes, given that actions are repeatedly sampled in all states (\cite{Watkins1992}). Therefore, it is important to note that in practice, the process described above this process should be repeated. New patients would be recruited, the estimated optimal dynamic treatment regime estimated from the previous trial would be used to assign treatments to each patient, then the optimal treatment regime would be estimated again using Q-learning. This updated optimal dynamic treatment regime would then be used to assign treatments to a new group of patients, and the process would be repeated again. 

% subsection steps_in_two_stage_q_learning (end)

\begin{algorithm}[ht]
  initialize $\hat{Q}_{K + 1}$ arbitrarily:

  $\hat{Q}_{K + 1} \gets 0$

  \medskip

 \For{$k$ in $K, \ldots, 1$}{
  Estimate the rewards that would occur if the optimal policy was  followed after $k$:

$ \hat{r}_{k} \gets r_{k} + \max_{A_{k+1}} \hat{Q}_{k+1}(A_{k+1}, H_{k+1})$

\medskip

Estimate the Q-function, $Q_{k}(A_{k}, H_{k})$, for the preceding stage using this reward as the outcome (e.g. through ordinary least squares).

\medskip

Estimate the optimal treatment(s) for each patient at stage $k$:

$\hat{A}^{opt}_{k} \gets \argmax_{A_{k}} \hat{Q}_{k}(A_{k}, H_{k})$
 }

 \caption{Q-learning}
\end{algorithm}

% section q_learning (end)

\section{Regression Trees using CART} % (fold)
\label{sec:rpart}

A decision tree is a graphical representation of nested \texttt{if-then} statements, with each ``decision'' being based on whether the \texttt{if} statement is true or false. A regression tree is a kind of decision tree where each \texttt{if-then} statement splits the data (or subset of the data created by a previous split) according to the value of a single covariate at a time. Since an \texttt{if} statement creates two possible outcomes (\texttt{TRUE} or \texttt{FALSE}), each split is binary and results in two \emph{daughter nodes}, two subsets of the data created according to the value of a particular covariate. Once the desired number of splits is performed, each \emph{terminal node} or \emph{leaf}, a node from which no further splits are made, is assigned an outcome (typically the mean outcome for each observation in that node). Unlike trees in nature, decision trees grow from the root node downward, as shown in the illustrative example below. Since in reinforcement learning, rewards are defined to be continuous, we focus on regression trees constructed using the CART procedure of \textcite{CART}.

% For example, a simple regression tree could be constructed with the following rules (adapted from \cite{apm}):
% \begin{verbatim}
% if Covariate A <= 2 then
% |   if Covariate B >= 34.2 then Outcome = 6
% |   else Outcome = 4.9
% else Outcome = 2.2
% \end{verbatim}

\subsection{Tree growing} % (fold)
\label{sub:tree_growing}

Our overarching goal in tree construction is to create nodes as homogeneous in the outcome as possible. This is because we will predict a single outcome for all observations in the terminal nodes, meaning nodes heterogeneous in the outcome will yield poor predictions. To achieve this we must determine:

\begin{enumerate}
  \item What covariate to use to define a split and what value of the covariate to split on
  \item When to stop splitting
  \item How to assign an outcome to each terminal node
\end{enumerate}

We begin with all of the data (the \emph{root node}) and evaluate the sum of squared errors that result from splitting based upon each unique value of each covariate:
\begin{equation}
  SSE = \sum_{i \in \text{node}_{L}} (y_{i} - \bar{y}_{L})^2 + \sum_{i \in \text{node}_{R}} (y_{i} - \bar{y}_{R})^2
\end{equation}

Where $\bar{y}_{L}$ is the average outcome in the left node, $\text{node}_{L}$ and $\bar{y}_{R}$ is the average outcome in the right node, $\text{node}_{R}$. We choose the split that minimizes the sum of squares error ($SSE$). This process is then repeated in both of the left and right nodes that result from the split. This feature of recursive splitting, or partitioning, of the data is why this method is also known as \emph{recursive partitioning}. Typically we continue splitting in this manner until the number of observations in a node falls below a threshold (e.g. 20 observations), and assign each terminal node the average outcome of training observations in that node.

\begin{algorithm}[!htbp]
\While{stopping criteria not met}{
\For{each terminal node}{
 \For{each $X_{j} \in X$}{
  \For{each possible split of $X_{j}$}{
    compute change in SSE resulting from split
  }
 }
 \If{reduction in SSE from split largest}{
  split node
  }{
 }
 add newly created nodes to set of terminal nodes
 }
}
 \caption{Regression tree growing algorithm}
\end{algorithm}

% subsection tree_growing (end)

\subsection{Tree pruning} % (fold)
\label{sub:tree_pruning}

The large tree resulting from the tree growing phase, $T_{0}$, typically overfits the data. To combat this, we prune back $T_{0}$ using a technique called cost complexity pruning.

The goal in cost-complexity pruning is to find, for each value of a complexity parameter $\alpha \geq 0$, the subtree $T \subset T_{0}$ created by collapsing any of $T_{0}$'s internal (non-terminal) nodes, which minimizes the cost complexity criterion:
%
\begin{equation}
    C_{\alpha}(T) = \sum_{m = 1}^{\abs{T}} \sum_{x_{i} \in \text{node}_{m}} (y_{i} - \bar{y}_{m})^2 + \alpha \abs{T}
\end{equation}
%
where $y_{i}$ is the outcome value for an observation in node $m$, $\bar{y}_{m}$ is the average outcome in node $m$, and $\abs{T}$ is the number of terminal nodes in subtree $T$. One can show that there is a unique subtree $T_{\alpha}$ that minimizes $C_{\alpha}(T)$ for each given $\alpha$ (\cite{esl}).

In order to find $T_{\alpha}$ for each $\alpha$, we use weakest link pruning. As the name implies, in weakest link pruning, we test out collapsing each internal node, choosing to actually collapse the the weakest link: the node that, if collapsed, produces the smallest increase in $\sum_{m = 1}^{\abs{T}} \sum_{x_{i} \in \text{node}_{m}} (y_{i} - \bar{y}_{m})^2$, the sum of squares of the whole tree. We continue in this fashion until we've returned to the root node. This sequence contains each $T_{\alpha}$.

With the $T_{\alpha}$s in hand, we choose the $\alpha$ (and hence $T_{\alpha}$) that minimizes the sum of square errors produced using cross validation. Alternatively, we can use choose the largest $\alpha$ (smallest $T_{\alpha}$) which is within one standard error of the minimum cross validated error.

\begin{algorithm}[!htbp]
\For{each $\alpha > 0$}{
\While{$T \supset $ root node}{
  compute change in SSE from collapsing each internal node in turn

  collapse node that produces the smallest increase in SSE (weakest link), save resulting tree
}
\For{each saved tree}{
 compute cross validation error
}
Choose the saved tree with the smallest cross validation error ($T_{\hat{\alpha}}$)
}
Pick the $T_{\hat{\alpha}}$ with the smallest cross validation error as final tree.

Or pick the smallest $T_{\hat{\alpha}}$ within one standard error of the $T_{\hat{\alpha}}$ with the smallest cross validation error
 \caption{Regression tree pruning algorithm}
\end{algorithm}


% subsubsection tree_pruning (end)

\subsection{Variable importance} % (fold)
\label{sub:variable_importance_in_cart}

Variable importance in trees can be measured by summing the overall reduction in the optimization criteria for each prediction (\cite{CART}). In regression trees, the optimization criteria is typically SSE, so we could sum the reductions in SSE from each splits made based on a particular covariate, repeating the process for every covariate.
%
% % subsection variable_importance_in_cart (end)


\subsection{Advantages and disadvantages} % (fold)
\label{sub:advantages_and_disadvantages_to_cart}

The main advantage of regression trees is their easy interpretation, even by non-experts, largely due to the convenient graphical tree representation. CART also intrinsically conducts feature selection as part of the model building process and easy handles many types of covariates without the need for pre-processing, creating dummy variables, or even specification of the form of the relationship between the covariates and the outcome. There are also methods to handle missing data specific to trees, see \textcite{esl} for details.

Trees however, tend to have lower predictive performance compared to other methods particularly in the regression setting. Part of the reason is that trees tend to be sensitive to changes in data, which is to say they have high variance (though ensemble methods like random forest, discussed below, exploit this property to achieve better performance). In the regression setting in particular, trees are hindered by a lack of smoothness and difficulty in capturing additive structures. Multivariate adaptive regression splines (MARS), which we will discuss next, can be viewed as a modification of the CART technique to overcome these issues.

% subsection advantages_and_disadvantages_to_cart (end)

\subsection{Illustrative example} % (fold)
\label{sub:cart-ex}

Let's examine CART, MARS, and random forest (below) using a simple sub-problem from the simulation described in detail below. Suppose we want to predict the change in the mass of the $i$th cancer patients' tumor from its initial mass to the mass after one month of treatment, $Y_{i} \equiv M_{i1} - M_{i0}$, given the dose of a drug, $D_{i}$, which they were (randomly) assigned. The true relationship is given by
\begin{equation}
  Y_{i} = 0.75 - 1.2 D_{i} + \epsilon_{i}, \quad i = 1, \ldots, 50
\end{equation}
Where $\epsilon_{i} \sim N(0, 0.05)$. 50 patients were simulated with random starting tumor masses sampled from a uniform distribution from 1 to 2, $M_{0} \overset{iid}{\sim} \text{Unif}(1, 2)$, and doses were sampled from a uniform distribution between 0 (none) and 1 (the maximum tolerable dose), $D \overset{iid}{\sim} \text{Unif}(0, 1)$. 50 additional patients were simulated in the same fashion as test data.

In this example we used stopping criteria of: (1) terminal nodes had to have at least 5 observations, and (2) nodes with fewer than 15 observations were not split. For pruning, we follow the ``one standard error'' rule, where we choose the smallest tree within one standard error of the tree with the minimum cross validation error.

\begin{figure}[!htbp]
\centering
  \includegraphics[width=0.8\textwidth]{figure/ex-cart-tree-1}

\caption[Regression tree fit to example data]{Regression tree fit to example data. For each split, the variable split upon is shown as a circle representing an internal node (with a numbered box giving the node a number). The values of the splitting variable that define resulting node membership are shown breaking the line connecting nodes (e.g. observations with $D \geq 0.585$ end up in node 2, while observations with $D < 0.585$ end up in node 5). Box plots show the distribution of responses in each terminal node (nodes 3, 4, 6, and 7, shown at the bottom of the tree)}\label{fig:ex-cart-tree}
\end{figure}

This produces the tree in Figure \ref{fig:ex-cart-tree}. Since the regression function is actually linear, the splits are intuitive: first we split the root node (node 1) at around the midpoint of the distribution of doses ($D = 0.585$), then we split the observations with doses higher than 0.585 (node 2) at about their median dose, 0.759, producing the terminal nodes 3 and 4. Similarly with doses less than 0.585 (node 5), we split at approximately the median dose (0.317), yielding terminal nodes 6 and 7.

\begin{figure}[!htbp]
\centering
  \includegraphics[width=0.75\textwidth]{figure/ex-plot-cart-1}

\caption[Predicted regression function for example data using CART]{Predicted regression function for example data using CART. The grey dots are the observations and the dotted line is the true relationship from which they were generated. The solid line connects the predicted values, which are shown with $\times$s.}\label{fig:ex-plot-cart}
\end{figure}

The resulting predicted regression function is shown as a solid line in Figure \ref{fig:ex-plot-cart}, with $\times$s showing the predicted value for each observation in the training data. The grey dots are the actual observations and the dotted line represents the true function from the observations were simulated. Note the piecewise constant form of the function, where all observations in a terminal node receive the same predicted value.

Using this model to predict the change in tumor masses, $Y$, for the test data results in an root mean squared error of about 0.117 and a coefficient of determination ($R^2$) of about 0.93. In practice, we would be well advised to relax our stopping criteria to allow smaller terminal nodes in this setting. In general, one only loses computing time by setting stopping criteria that allow very complicated trees in the growing phase, since branches that aren't predictive will be pruned (we did not here to keep the tree simple for the purposes of illustration).

% subsection example (end)


% section rpart (end)

\section{Multivariate adaptive regression splines (MARS)} % (fold)
\label{sec:mars}

MARS (\cite{mars}) can be viewed as a modification of the CART procedure to improve performance in the regression setting, or as a generalization of stepwise linear regression methods that incorporates automatic modeling of interactions. MARS accomplishes this latter feature through modeling covariates as piecewise linear basis functions and their products. These piecewise linear basis functions are of the form
%
\begin{equation} \label{eq:bases}
  (x - t)_{+} \text{ and } (t - x)_{+}
\end{equation} where
%
\begin{equation}
  (Z)_{+} = \max(Z, 0) = \begin{cases}
  Z, & \text{if } Z > 0 \\
  0, & \text{otherwise}
  \end{cases}
\end{equation}
The set in equation \ref{eq:bases} is sometimes called a \emph{reflected pair} because the values they take on are symmetric (reflected) across $t$. Each function in the pair is called a \emph{hinge} function, and can alternatively be denoted $h(x - t)$ and $h(t - x)$ respectively. These hinge functions are joined at $t$, a $knot$.

\subsection{Forward pass} % (fold)
\label{sub:forward_pass}

As in forward selection methods, in MARS, we begin constructing our model with only a constant:
\begin{equation}
  f(X) = \beta_{0}
\end{equation}
Then, we consider adding a pair of piecewise linear functions made by splitting some covariate $X_{j}$ at a knot placed at one of the observed values of $X_{j}$, $x_{ij}$:
\begin{equation}
\beta_{1} (X_{j} - t)_{+} + \beta_{2}(t - X_{j})_{+}, \ i = 1, 2, \ldots, n; \ j = 1, 2, \ldots, p.
\end{equation}
To determine which predictor to add and which knot to split upon, each of the $j$ predictors, split at each observed value $x_{ij}$ is evaluated in turn by adding each pair to the model and calculating the training error, e.g. the SSE. The covariate and split point that cause the greatest reduction in error are added to the model.

Henceforth, we consider adding a pair piecewise linear functions with general form
%
\begin{equation} \label{eq:gen-pairs-add}
  \beta_{M + 1} h_{\ell}(X) \cdot (X_{j} - t)_{+} + \beta_{M + 2} h_{\ell}(X) \cdot (t - X_{j})_{+}, \ h_{\ell}(X) \in \mathcal{M}, \ t \in \{x_{ij}\}.
\end{equation}
%
Where $\mathcal{M}$ is the set of hinge functions (or products of hinge functions) already in the model. Note that this equation also holds for the first step, in which case $h_{\ell}(X) = h_{0}(X) = 1$. As before, we add the pair that causes the greatest reduction in training error. To simplify the set of models considered, we may provide a limit on the degree, or order of interactions we are interested in considering. For example with degree = 1, we only consider an additive model (all $h_{\ell}(X) = h_{0}(X) = 1$), with degree = 2, we consider a maximum of two-way interactions, and so on.
Pairs are added until a user-defined limit on the number of terms in the model is reached, or the reduction in training error is smaller than some predefined threshold.

The resulting MARS regression function is of the form
\begin{equation}
  f(X) = \beta_{0} + \sum_{m = 1}^{M} \beta_{m} h_{m}(X),
\end{equation}
where $M$ is the number of terms in the model, and $h_{m}(X)$ is a hinge function like one of those in equation \ref{eq:bases} or a product of such functions.

% subsection forward_pass (end)

\subsection{Backward pass} % (fold)
\label{sub:backward_pass}

Usually, the function produced by the forward pass is too large and overfits the data, we use a pruning (backward deletion) procedure analogous to backward selection linear regression methods. For each term $h_{m}(X)$ in the model, we estimate how much the error would increase by removing it, then remove the term for which removal increases the error the least. Once we've removed one term, we repeat this procedure and delete another term. At each stage of this procedure we obtain $\hat{f}_{\lambda}(X)$, the best model of size $\lambda$ (best model with $\lambda$ terms). Note that we do not proceed backwards along the path through which the covariates were added (indeed we add pairs of hinge functions on at a time, but remove them one by one).

To determine the optimal number of terms, $\lambda$, we can use a resampling technique (e.g. cross validation) but for computationally efficiency, we often use generalized cross validation (GCV).

% subsection backward_pass (end)

\subsection{Generalized cross validation} % (fold)
\label{sub:generalized_cross_validation}

Generalized cross validation is a computational shortcut for linear regression models, which produces an error that approximates the leave-one-out cross-validated error. For MARS, the generalized cross-validation criterion is defined as
\begin{equation}
  GCV(\lambda) =
    \frac{
      \sum_{i = 1}^{N}(y_{i} - \hat{f}_{\lambda}(x_{i}))^2
    }{
      (1 - M(\lambda)/N)^2
    }
\end{equation}
where $M(\lambda)$ is the effective number of parameters in the model, accounting for both the actual parameters and parameters used in selecting knot positions. Simulations and mathematical results tell us that $M(\lambda)$ should be set to $r + 3K$, the number of terms plus three times the number of knots, but can be set to $r + 2K$ when the degree = 1; when the model is restricted to be additive (\cite{esl}).

% subsection generalized_cross_validation (end)

\subsection{Relationship to CART} % (fold)
\label{sub:relationship_to_cart}

As mentioned above, MARS can also be viewed as a modification of CART to improve performance in the regression setting. If we modified the MARS procedure to consider reflected pairs of step functions of the form $I(x - t > 0)$ and $I(t - x > 0)$ instead of the piecewise linear basis functions and then replaced the term already in the model involved in a new interaction term by the new interaction term (making the original term unavailable for further interactions), then the forward pass in MARS is equivalent to the CART tree-growing algorithm. In this case, the multiplication of a step function by a pair of reflected step functions is equivalent to splitting a node.

% subsection relationship_to_cart (end)

\subsection{Variable importance} % (fold)
\label{sub:variable_importance}

Similar to CART, we can measure the importance of each variable by summing the reduction in the GCV statistic (or SSE or other metric) whenever a term with the variable is added (or equivalently the amount it increases as all terms with containing a given variable are removed).

% subsection variable_importance (end)

\subsection{Advantages and disadvantages of MARS} % (fold)
\label{sub:advantages_of_mars}

MARS has many of the same advantages as CART, in that it requires very little pre-processing of data, it performs variable selection and models interactions as a part of the model building process, and the models produced are quite interpretable. This last point holds even for models with interactions since products of hinge functions are only nonzero when all hinge functions involved in the product are nonzero, allowing the term to operate only over a relatively small subspace of the covariates involved.

However, the hinge functions of MARS may not be flexible enough to model smooth functions as accurately as some other methods (this can be addressed by bagging, discussed below). Also, higher order interactions will only enter the model if their lower order interactions improve predictive performance, and this need not be true in practice. As with trees, correlated predictors, which don't significantly impact performance, but can complicate interpretation. Suppose there were two perfectly correlated predictors to consider. Then the choice between the two at any step is essentially random. This could hinder interpretation because the same piece of information may show up in different parts of the model under different names.

% subsection advantages_of_mars (end)

\subsection{Illustrative example} % (fold)
\label{sub:mars-ex}

Returning to our change in tumor mass example from above, let's fit a regression equation using MARS. Here, no further terms were added if there were already 21 terms in the model or adding additional terms improved $R^2$ by less than 0.001. Terms were pruned using generalized cross validation as discussed above.

\begin{figure}[!htbp]
\centering
  \includegraphics[width=0.75\textwidth]{figure/ex-plot-mars-1}

\caption[Predicted regression function for example data using MARS.]{Predicted regression function for example data using MARS. As in Figure \ref{fig:ex-plot-cart}, the grey dots represent observations, the dotted line represents the true function from which observations were simulated, the solid line represents the predicted regression function, and the $\times$s represent predicted values for each observation.}\label{fig:ex-plot-mars}
\end{figure}

The resulting predicted regression function is shown in Figure \ref{fig:ex-plot-mars} as a solid line. Grey dots again represent observations, the dotted line represents the true relationship from which data were simulated, and predicted values for each observation are represented by $\times$s. The fitted MARS equation is
\begin{equation}
  \label{eq:mars-eqn}
  \hat{\operatorname{E}}[Y \mid D] \approx -0.24 + 1.24 (0.81 - D)_{+} -1.64 (D - 0.87)_{+}
\end{equation}
Note that the hinges don't meet because the hinges that entered paired with each remaining hinge were removed in the pruning/backward pass phase. The gap between hinges is shown in our plot as a horizontal line of $Y = -0.24$ for $0.81 < D < 0.87$.

Using this model to predict the testing data yields a root mean squared error of 0.037 and a coefficient of determination ($R^2$) of 0.99. As these measures indicate, MARS does a much better job of capturing the linear nature of the relationship between $Y$ and $D$ than CART does, with many fewer ``splits''. Note also that we can restrict MARS to only consider predictors to enter as linear terms (without splitting into hinge functions), which we would probably do here given that the fitted regression line is nearly linear anyway, and would then be easier to interpret.

% subsection example (end)

% section mars (end)

\section{Random forest} % (fold)
\label{sec:random_forest}

\subsection{Bagging} % (fold)
\label{sub:bagging}

As mentioned above, single trees tend to have quite high variance (small changes in the data can produce very different trees), however when grown sufficiently deep or bushy, they can have relatively low bias. Bootstrap aggregating, or \emph{bagging} for short, is a general technique that is useful whenever a modeling technique has these properties (high variance, low bias).

Consider a collection of independent and identically distributed random variables, $X_{1}, X_{2}, \ldots, X_{n}$, each with variance $\sigma^2$ and sample mean $\bar{X}$. It's easy to show that
\begin{equation}
  \operatorname{Var}[\bar{X}] = \frac{\sigma^2}{n},
\end{equation}
the variance of the sample mean is lower by a factor of $n$ than the variance of any single observation. If we could build trees on many different samples then average the results, we could exploit this property to drastically reduce the variance and therefore increase performance.

Typically, however, we only have one sample to work with, but we can take $B$ bootstrap samples of our one sample to approximate many different training samples. We could then build a model on each sample, then aggregate the results from each model into a single prediction. In the case of regression problems, we would average the predicted outcome for each test observation from each model.

\begin{algorithm}[ht]
\For{$i$ in 1 to $B$}{
  Take a bootstrap sample of the data \\
  Fit model to this sample (e.g. grow an unpruned tree)
 }
 \caption{Bagging}
\end{algorithm}

Bagging also provides a built-in way to estimate the test error by only averaging predictions for any given tree using the \emph{out-of-bag sample}, the observations that were not in the bootstrap sample used to train that tree (about 1/3 of the observations on average). This out-of-bag sample typically approximates the cross validation estimate of the error rate well, but requires much less computation.

Unfortunately, we can't in practice achieve a $B$ fold decrease in the variance from a single tree because our trees are not independent. Suppose there was a single very strong predictor. For any tree grown from a bootstrap sample, the first few splits would then tend to be made on this strong predictor. This in turn strongly influences the remaining shape of the tree, leading to correlated trees across bootstrap samples.

% subsection bagging (end)

\subsection{Random forest} % (fold)
\label{sub:random_forest}

Statistically, we can decrease correlation by introducing randomness. So \textcite{rf} suggested that we decrease correlation between trees built on bootstrap samples by only considering a random subset $m_{try} \subset p$ of covariates to split upon for each split instead of considering all $p$.

\begin{algorithm}[ht]
\For{$i$ in 1 to $B$}{
  take a bootstrap sample of the data \\
  Grow a tree on this sample: \\
  \While{stopping criteria not met}{
  \For{each split}{
    randomly select $m_{try}$ of $p$ original covariates \\
    split on a covariate in $m_{try}$ causing largest decrease in SSE
   }
  }

  (do not prune)
 }
 \caption{Random forest}
\end{algorithm}

This generally leads to better performance than bagging alone and often approaches the performance of more complicated techniques. How should be choose $B$? There is little danger of overfitting by growing more trees in random forest, so $B$ is typically set at a large enough number for the error rate to level off, \textcite{apm} recommend starting at 1000. Recommendations for $m_{try}$ are often set at a default of $\sqrt{p}$ or $p/3$, the latter specifically recommended for regression problems, though in practice $m_{try}$ should be chosen using resampling techniques. In the case of bagging, there is typically little gained after $B = 10$ or so. \textcite{apm} recommend setting $B = 50$.

% subsection random_forest (end)

\subsection{Variable importance} % (fold)
\label{sub:variable_importance_rf}

\textcite{rf} originally proposed randomly permuting one variable at a time in the out-of-bag sample for each tree, then calculating the reduction of predictive performance compared to the non-permuted out-of-bag sample. These differences for each tree would then be averaged across the whole forest and used to rank variables importance (higher reduction, more important). We could also extend the variable importance measure for a single tree to the whole forest by averaging the decrease in SSE for each split upon a given variable over the forest (higher decrease, more important).

% subsection variable_importance (end)

\subsection{Advantages and disadvantages} % (fold)
\label{sub:advantages_and_disadvantages_rf}

Random forests and bagging give significantly more accurate predictions over a single tree, but are also significantly harder to interpret. As with MARS and single trees, where correlated predictors show up is unpredictable and this can dilute variable importance. For example if two perfectly correlated variables were considered, the variable importance for each would be half of what it would be, if it alone had been considered.

% subsection advantages_and_disadvantages_to_random_forest (end)

\subsection{Illustrative example} % (fold)
\label{sub:example_rf}

\begin{figure}[!htb]
\centering
  \includegraphics[width=0.75\textwidth]{figure/ex-plot-rf-1}

\caption[Predicted regression function for example data using Random Forest]{Predicted regression function for example data using Random Forest. As in Figures \ref{fig:ex-plot-cart} and \ref{fig:ex-plot-mars}, the grey dots represent observations, the dotted line represents the true function from which observations were simulated, the solid line represents the predicted regression function, and the $\times$s represent predicted values for each observation.}\label{fig:ex-plot-rf}
\end{figure}

Returning to our change in tumor mass example from above, let's fit a regression equation using random forest. Actually, in this case since there is only one predictor, random forest is equivalent to bagging and therefore fewer trees will suffice. Here we grow 100 trees each that stop splitting when splitting results in nodes with fewer than 5 observations.

The predicted regression function averaged over the 100 trees is shown in Figure \ref{fig:ex-plot-rf}. Again, the observations are given by grey dots, the true function from which data were simulated is shown as a dotted line, the predicted observations are shown as $\times$s which are connected by a solid line. Notice how averaging the bagged trees yields a line much closer to the truth than the single tree shown above, though each tree was grown using similar stopping criteria as the CART example.

When using this model to predict the test data we obtain a root mean squared error of 0.045 and an $R^2$ of 0.984. This compares much more favorably to MARS than a single tree, however it comes at the cost of a lack of clarity in the relationship between $Y$ and $D$ in the model.

% subsection example (end)

% section random_forest (end)


\section{Simulation} % (fold)
\label{sec:simulation}

Largely inspired by \textcite{crt} and \textcite{nsclc}, I estimated optimal dynamic treatment regimes for a cancer clinical trial for an advanced generic cancer. This trial had three stages of treatment, each stage being one month long. A dose of a single drug was given at the beginning of each stage, potentially a different dose for each stage. My primary goal was to find dynamic treatment regimes that would maximize survival time. To achieve this, I first simulated a trial to serve as training data where at the beginning of each of the three months ($t = 0, 1, 2$), patients' tumor masses and qualities of life were measured, and each patient was assigned a random dose of the drug.

% \begin{figure}
%      \begin{tikzpicture}[->, >=stealth', auto, node distance=1.5cm, minimum size=1pt,
%     pt node/.style={rounded corners, draw},
%     pt node img/.style={rounded corners, dashed, draw},
%     dose node/.style={circle, draw},
%     surv node/.style={diamond, draw},
%     r node/.style={star, draw}]
%
%     \node[pt node]    (M0) {$M_{0}$, $W_{0}$};
%     \node[dose node]  (D0) [above of = M0] {$D_{0}$};
%     \path (D0) edge (M0);
%     \node[pt node]    (M1) [right of = M0, xshift = 1cm] {$M_{1}$, $W_{1}$};
%     \node[r node]     (R1) [below of = M1, inner sep = -4pt, yshift = -0.5cm] {$R_{1} = 0$};
%     \path (M0) edge (M1) (M1) edge (R1);
%     \node[dose node]  (D1) [above of = M1] {$D_{1}$};
%     \path (D1) edge (M1);
%     \node[pt node] (M2) [right of = M1, xshift = 1cm] {$M_{2}$, $W_{2}$};
%     \path (M1) edge (M2);
%     \node[r node]     (R2) [below of = M2, inner sep = -4pt, yshift = -0.5cm] {$R_{2} = 0$};
%     \path (M2) edge (R2);
%     \node[dose node]  (D2) [above of = M2] {$D_{2}$};
%     \path (D2) edge (M2);
%     \node[surv node]  (S3) [right of = M2, xshift = 0.8cm] {$S_{3}$};
%     \node[r node]     (R3) [right of = S3] {$R_{3}$};
%     \path (M2) edge (S3) (S3) edge (R3);
%
%
%     \draw [->, dashed] (R3) edge (Q3);
%     \node (Q3) [below right of = R3] {$\hat{R}_{3} = R_{3}$};
%     % (M2) edge [bend right = 30] (Q3)
%
%
%
%     \draw [->, dashed] (Q3) edge [bend right = 30] node {$\hat{Q}_{3} = \operatorname{E}[\hat{R}_{3}|D_{2}, M_{2},W_{2}]$} (Q2);
%
%
%
%     \node (Q2) [below right of = R2, xshift = 1cm, yshift = -0.5cm] {$\hat{R}_{2} = R_{2} +  \max_{D_{2}} \hat{Q}_{3}$};
%     \draw [->, dashed] (R2) edge (Q2);
%
%
%
%     \draw [->, dashed] (Q2) edge [bend left = 30] node {$\hat{Q}_{2} = \operatorname{E}[\hat{R}_{2}|D_{1}, M_{1},W_{1}]$} (Q1);
%
%
%
%     \node (Q1) [below right of = R1, yshift = -1cm, xshift = -1cm] {$\hat{R}_{1} = R_{1} +  \max_{D_{1}} \hat{Q}_{2}$};
%     \draw [->, dashed] (R1) edge (Q1);
%
%     \node (Q0) [below of = M0, yshift = -3.5cm, xshift =1cm] {$\hat{Q}_{1} = \operatorname{E}[\hat{R}_{1}|D_{0}, M_{0},W_{0}]$};
%
%     \draw [->, dashed] (Q1) edge (Q0);
%
%   \end{tikzpicture}
% \end{figure}

\subsection{Patient Model} % (fold)
\label{sub:vpm}

% The goals of the patient model were to capture:
%
% \begin{enumerate}
%   \item Treatment kills tumor cells but increases toxicity (decreases quality of life)
%   \item Tumors grow in the absence of treatment (or with too little treatment)
%   \item Toxicity lessens and quality of life improves in absence of treatment
%   \item Better quality of life/general health reduces the growth rate of tumor cells (and vice versa)
%   \item Tumors decrease quality of life, and larger tumors cause larger decreases
% \end{enumerate}

\subsubsection{Transition functions} % (fold)
\label{ssub:transition_functions}

Patient toxicity measured at month $t$, $W_{t}$, which I define as the negative of wellness or quality of life\footnote{For simplicity, I take wellness and quality of life to be equivalent and exactly the opposite of toxicity}, was modeled as a function of tumor mass and dosage of treatment:
%
\begin{equation}
W^{*}_{t} = 0.1 M_{t-1} + 1.2 (D_{t-1} - 0.5) + W_{t - 1}
\end{equation}
\begin{equation}
W_{t} = \begin{cases}
  W^{*}_{t} &\text{if } W^{*}_{t} > 0 \\
  0 &\text{if } W^{*}_{t} \leq 0
\end{cases}
\end{equation}
This model represents the belief that higher tumor masses at month $t-1$, $M_{t-1}$, increase the measured toxicity at month $t$, $W_{t}$ (by decreasing patient wellness). For a given $M_{t-1}$, doses at month $t-1$, $D_{t -1}$, above 0.5 increase $W_{t}$, while $D_{t -1}$ below 0.5 decrease $W_{t}$ due to fewer toxic effects from treatment. Further, $W_{t}$ is bounded by 0, which corresponds to no toxic effects.

Tumor mass at month $t$, $M_{t}$, was modeled as a function of toxicity measured the previous month, $W_{t-1}$, and dose assigned the previous month $D_{t-1}$:
%
\begin{equation}
M^{*}_{t} = [0.15 W_{t-1} - 1.2 (D_{t-1} - 0.5) + M_{t - 1}] I(M_{t-1} > 0)
\end{equation}
\begin{equation}
M_{t} = \begin{cases}
  M^{*}_{t} &\text{if } M^{*}_{t} > 0 \\
  0 &\text{if } M^{*}_{t} \leq 0
\end{cases}
\end{equation}
%
lower overall health (higher $W_{t-1}$) leads to greater tumor growth, while for a given $W_{t-1}$, $D_{t-1}$ above 0.5 decreases $M_{t}$ and $D_{t-1}$ below 0.5 allows $M_{t}$ to increase, with $M_{t}$ bounded by 0 since mass is strictly positive.

% subsubsection transition_functions (end)

\subsubsection{Survival model} % (fold)
\label{ssub:survival_model}

Survival times (in months) at month $t$ were generated from an exponential distribution. The rate parameter for this distribution was modeled as a function of the tumor mass and toxicity which would result at time $t+1$:
\begin{equation}
  \lambda_{t}(M_{t+1}, W_{t+1}) = \exp(-5.5 + W_{t+1} + 1.2 M_{t+1} + 0.75 W_{t+1} M_{t+1}).
\end{equation}
This indicates that we take tumor mass to be more important in survival than toxicity. The interaction between tumor mass and toxicity reflects the belief that higher levels of both tumor mass and toxicity lead to a greater reduction in survival than either alone.

% subsubsection survival_model (end)

% subsection vpm (end)

\subsection{Basic scenario} % (fold)
\label{sub:basic_setup}

For the simulated trial that would serve as training data, I began by simulating random doses of treatment for 1000 patients for each of the three months of treatment. The doses were randomly chosen from a uniform distribution over (0, 1) at the beginning of each month:
%
\begin{equation}
  D_{t} \overset{iid}{\sim} \text{Unif}(0, 1), \quad t = 0, 1, 2
\end{equation}
%
here $D_{t} = 0$ represents no treatment, and $D_{t} = 1$ represents the maximum tolerable dose.

Each patient's initial tumor mass, $M_{0}$, and negative of quality of life (toxicity), $W_{0}$, were generated independently from uniform distributions between 0 and 2:
%
\begin{equation}
  W_{0} \overset{iid}{\sim} \text{Unif}(0, 2), \qquad
  M_{0} \overset{iid}{\sim} \text{Unif}(0, 2)
\end{equation}

At each month $t$, the next month's tumor mass, $M_{t + 1}$, and toxicity, $W_{t + 1}$, were computed in response to dose at month $t$, $D_{t}$, for each patient as described above. Similarly, the rate parameter for the survival distribution, $\lambda_{t}(M_{t + 1}, W_{t + 1})$, was updated for each patient from these next month's tumor masses and toxicities. Survival times, $S_{t}$ were then randomly sampled from the exponential distribution with the just computed rate parameter:
\begin{align}
  S_{t} \sim ~ &\text{Exp}(\lambda_{t}(M_{t + 1}, W_{t + 1})) \\
  = ~ &\text{Exp}(\exp(-5.5 + W_{t+1} + 1.2 M_{t+1} + 0.75 W_{t+1} M_{t+1}))
\end{align}

If $S_{it} \leq 1$ for patient $i$ (i.e. the patient would not survive another month), the reward received was computed as the total log survival time: log of the total number of months the patient had survived (including the fraction of a month before their death, $S_{it}$). If patient $i$ survived up to the final month of treatment $t = 2$, the rewards were computed as $\log(S_{i2} + 2)$, the log of the simulated survival time after the final treatment plus the the number of months already elapsed.
\begin{equation}
  R_{t + 1} = \begin{cases}
    \log(S_{t} + \sum_{j = 0}^{t} j) & \text{if } S_{t} \leq 1 \text{ or } t = 2 \\
    0 & \text{otherwise}
  \end{cases}
\end{equation}

Note that I use the log of the survival time as a continuous reward (and hence outcome) and do not model it as a censored time-to-event outcome.

% subsection basic_setup (end)


\subsection{Interaction scenario} % (fold)
\label{sub:subgroups_interaction}

The interaction scenario was identical to the basic scenario just described with the addition of two baseline covariates, $X_{1}$ and $X_{2}$ which were simulated from uniform distributions over (0, 1):
\begin{equation}
  X_{1}, X_{2} \overset{iid}{\sim} \text{Unif}(0, 1)
\end{equation}
Using the values of these covariates, four approximately equally sized subgroups were constructed:
\begin{description}
  \item [$X_{1} < 0.5 \ \& \ X_{2} < 0.5$:] patients simulated identically to those in the basic scenario.
  \item [$X_{1} > 0.5 \ \& \ X_{2} < 0.5$:] these patients are 50\% more sensitive to the effects of the drug:
   \begin{equation}
   W^{*}_{t} = W'_{t} = 0.1 M_{t-1} + 1.2 (1.5 D_{t-1} - 0.5) + W_{t - 1}
   \end{equation}
   \item [$X_{1} < 0.5 \ \& \ X_{2} > 0.5$:] the treatment is 50\% more effective for these patients:
\begin{equation}
M^{*}_{t} =  M'_{t} = [0.15 W_{t-1} - 1.2 (1.5 D_{t-1} - 0.5) + M_{t - 1}] I(M_{t-1} > 0)
\end{equation}
   \item [$X_{1} > 0.5 \ \& \ X_{2} > 0.5$:] the drug is 50\% more effective for these patients, but they are also 50\% more sensitive to its effects:
   \begin{align}
   W^{*}_{t} = W'_{t} &= 0.1 M_{t-1} + 1.2 (1.5 D_{t-1} - 0.5) + W_{t - 1} \\
   M^{*}_{t} = M'_{t} &= [0.15 W_{t-1} - 1.2 (1.5 D_{t-1} - 0.5) + M_{t - 1}] I(M_{t-1} > 0)
   \end{align}
\end{description}

% subsection subgroups_interaction (end)

\subsection{High-dimensional noise scenarios} % (fold)
\label{sub:noise_variables}

In the noise scenarios, 100 additional variables: $Z = (Z_{1}, \ldots, Z_{10})$ and $V = (V_{1}, \ldots, V_{90})$ were also simulated with distributions as follows:
\begin{align}
  Z_{1}, \ldots, Z_{5} &\overset{iid}{\sim} N(1, 1) \\
  Z_{6}, \ldots, Z_{10} &\overset{iid}{\sim} N(-1, 1) \\
  V_{1}, \ldots, V_{90} &\overset{iid}{\sim} N(0, 1)
\end{align}
That is, $Z_{1}, \ldots, Z_{5}$ were sampled independently from a normal distribution with mean 1 and standard deviation 1, $Z_{6}, \ldots, Z_{10}$ were sampled independently from a normal distribution with mean -1 and standard deviation 1, and $V_{1}, \ldots, V_{90}$ were sampled independently from a standard normal distribution. These covariates were used in two separate scenarios described below.

\subsubsection{Noise scenario} % (fold)
\label{ssub:pure_noise}

In the noise scenario, the $Z$ and $V$ variables above were made available to the models, but had no effect on $W_{t}, M_{t}$, or $S_{t}$.

% subsubsection pure_noise (end)

\subsubsection{Predictive noise scenario} % (fold)
\label{ssub:predictive_noise}
In the predictive noise scenario, the $Z$ and $V$ variables above were made available to the models and the $Z$ variables had a small influence on the rate parameter in the survival distribution:
\begin{equation}
  \lambda'_{t}(M_{t+1}, W_{t+1}) = \exp\del{-5.5 + W_{t+1} + 1.2 M_{t+1} + 0.75 W_{t+1} M_{t+1} + 0.05 \sum_{i = 1}^{10} Z_{i}}
\end{equation}
but did not change the optimal dose, as this modification only shifts the expected survival up or down.

% subsubsection predictive_noise (end)

% subsubsection noise_variables (end)

\subsubsection{Both interaction and noise scenarios} % (fold)
\label{ssub:subsubsection_name}

The interaction and noise scenarios were also combined together, to create the same subgroups as defined above both in the presence of pure noise, and in the presence of predictive noise, as described above.

% subsubsection ssubsubsection_name (end)


\subsection{Tuning parameters \& details of model fit} % (fold)
\label{ssub:tuning_parameters_for_interaction_scenario}

\begin{description}
  \item [CART:] Nodes with 15 or fewer observations were not split, nor were splits made if they produced nodes with fewer than 5 observations, or did not increase the overall $R^2$ by at least $10^{-5}$.
  In the pruning step, the $T_{\alpha}$ with the smallest 10 fold cross validation error was chosen as the final tree. This was achieved via the \texttt{rpart} package (\cite{rpart}) in \textsf{R} (\cite{R}).
  \item [MARS:] Only interactions with the treatment variable, $D_{t}$, were allowed, and these were restricted to second degree interactions. The forward pass was stopped if more than 200 terms were created, or further terms would decrease the $R^2$ by less than 0.001. The number of terms in the model, $\lambda$, was chosen using generalized cross validation. Modeling was performed with the \texttt{earth} package (\cite{earth}) in \textsf{R} called through the \texttt{caret} package (\cite{caret}).
  \item [RF:] Initially 500 trees were grown, with $D_{t}$ forced to be considered at each split and the out-of-bag samples used to choose $m_{try}$ from an even grid of five values from 2 to $p$. However, in each scenario, $m_{try} = p$ was at or very near the minimum out-of-bag error, so $m_{try} = p$ (bagging) was performed with with 250 trees. Trees were grown until further splits would result in terminal nodes with less than five observations. Modeling and resampling was performed using the \texttt{caret} package in \textsf{R} to call the \texttt{ranger} package (\cite{ranger}).
  % \begin{description}
  %   \item [Basic setup:] the number of parameters to consider at each split, $m_{try}$, was fixed at 1 ($\approx \sqrt{p}$) plus \texttt{dose}.
  %   \item [Interaction only:] $m_{try}$ fixed at 1 ($\approx \sqrt{p}$) plus \texttt{dose}.
  %   \item [All noise scenarios:] $m_{try}$ was fixed at 10 ($\approx \sqrt{p}$), plus the treatment variable \texttt{dose}
  % \end{description}
\end{description}



\subsection{Training procedure} % (fold)
\label{sub:procedure}

With the the survival times resulting from each simulated trial for each scenario listed above, Q-learning was applied using each of CART, MARS, and random forest to estimate the Q-functions at each stage. State signals were assumed to be Markov, so only the covariates from a particular stage were used in fitting the corresponding Q-function. The fitted models for each stage under each scenario were saved for estimating optimal treatments for patients in the validation set.  Maximum rewards in each stage of Q-learning were estimated by generating predicted rewards from the set of doses $D_{t} = 0, 0.01, 0.02, \ldots, 1$ and choosing the largest.

To quantify the influence the training data have on the resulting estimated optimal dynamic treatment regimes, I repeated the processes described in the preceding paragraph for 100 unique training sets each with 1000 patients.

% subsection procedure (end)

\subsection{Validation} % (fold)
\label{sub:validation}

Initial tumor masses ($M_{0}$) and toxicities ($W_{0}$) for 2000 new patients, were simulated identically to those in each scenario for the training data. In order to make treatment regimes more comparable, I then made copies of these 2000 individuals, one set of 2000 for each of the following regimes:

\begin{description}
  \item [10 constant dose regimes:] the same doses of $0.1, 0.2, \ldots,$ or 1 given at each stage
  % \item [``One-on-one-off'':] an alternating dose regime starting at the maximum dose (1), switching the dose to 0 for next stage, and repeating through the end of the trial.
  \item [Best:] the dose that maximizes the expected survival at each month, given complete knowledge of the transition functions and their influence on survival. Doses were chosen by considering all possible sequences of three doses and choosing the sequence that produced the largest expected survival time, with each dose chosen from the set $\{0, 0.01, 0.02, \ldots, 1\}$. Sequences also could not have any intermediate survival times leading to death (being less than one month).
  \item [CART, MARS, RF:] Out of doses from the set $\{0, 0.01, 0.02, \ldots, 1\}$, the dose corresponding to the maximum predicted rewards for each of the 100 CART, MARS, and random forest models for each stage.
\end{description}

The transition and survival functions were identical to the training data, with one exception: to further increase the comparability between regimes, the expected survival time was used as the actual survival time (and the determination of whether a participant had died), rather than the survival time using random draws from an exponential distribution.

To compare the regimes, I calculated the arithmetic mean survival time for the 2000 test patients under each treatment regime. I chose the arithmetic mean because it is more sensitive to very large and very small values, which in this setting should play a larger role. This is because a regime that produces very short survival times for one subgroup of patients but has a median or geometric mean close to another regime that does not is worse relative to our goals. I then calculated the mean and standard deviation of the 100 resulting mean survival times for each modeling technique.

\subsubsection{Variable importance} % (fold)
\label{ssub:variable_importance}

Variable importance was calculated for each model at each stage, as a percentage of the most important variable. For the CART models, variable importance was calculated as the total reduction in SSE resulting from each split on a particular variable. For the MARS models, the importance of each variable was calculated as the increase in SSE which would result from removing each term with a particular variable in it. Variable importance in each tree in the random forest models was calculated in the same way as a single CART tree, then these importances were averaged across all trees in the forest.

% subsubsection variable_importance (end)

% subsection validation (end)

% section simulation (end)

\section{Simulation Results} % (fold)
\label{sec:simulation_results}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\textwidth]{figure/results-no-int-1}
  \caption[Mean months of survival under each regime for scenarios without interaction]{Mean months of survival under each regime for the scenarios without interaction, log scale. The mean months of survival on the test set (initial tumor masses and toxicities for 2000 patients) for the regimes estimated using Q-learning (MARS, RF--here equivalent to bagging, and CART), each of the 100 treatment regimes estimated from each of the 100 training sets are shown in box plots. The best regime and the constant dose regimes ($1, 0.9, \ldots$, 0.1) do not vary across training set and therefore have only one mean survival time for the test set. Observations more than $1.5 \times IQR$ from either hinge (lower or upper quartile) are shown as points.}\label{fig:results-no-int}
\end{figure}

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\textwidth]{figure/results-int-1}
  \caption[Mean months of survival under each regime for scenarios with interaction]{Mean months of survival under each regime for scenarios with interaction, log scale. As in Figure \ref{fig:results-no-int}, mean months of survival for the regimes estimated using Q-learning (MARS, RF--here equivalent to bagging, and CART), each of the 100 treatment regimes estimated from each of the 100 training sets are shown in box plots. The best regime and the constant dose regimes ($1, 0.9, \ldots$, 0.1) do not vary across training set and therefore have only one mean survival time for the test set. Observations more than $1.5 \times IQR$ from either hinge (lower or upper quartile) are shown as points.}\label{fig:results-int}
\end{figure}


%latex.default(., file = "", dec = 1, caption = cap, caption.lot = cap_toc,     label = "tab:rewards", where = "!htbp", rowname = NULL, colheads = col_heads,     booktabs = T)%
\begin{table}[!htbp]
  \caption[Mean survival times under each scenario]{Mean months of survival under each scenario (in months), averaged over 2000 test patients for each regime. Each test set of 2000 had identical initial tumor masses and toxicities ($M_{0}$, $W_{0}$). Best is the optimal dose sequence obtained from evaluating every possible three dose sequence. MARS, RF (random forest, which is equivalent to bagging in these scenarios), and CART (regression trees using the CART procedure) represent the average survival times when using the optimal dose regime estimated from Q-learning using each method to fit the Q-functions, averaged over the 100 training set replicates. B is the basic scenario, N is noise scenario, PN is the predictive noise scenario, I is the interaction scenario, I+N is the interaction and noise scenario, and I+PN is the interaction and predictive noise scenario. Each scenario is described in detail in section \ref{sec:simulation}.\label{tab:rewards}}

\centering
\begin{tabular}{lrrrrrr}
\toprule
\multicolumn{1}{c}{Regime}&\multicolumn{1}{c}{B}&\multicolumn{1}{c}{N}&\multicolumn{1}{c}{PN}&\multicolumn{1}{c}{I}&\multicolumn{1}{c}{I+N}&\multicolumn{1}{c}{I+PN}\tabularnewline
\midrule
Best&$60.0$&$60.0$&$61.1$&$79.5$&$79.5$&$81.1$\tabularnewline
MARS&$39.8$&$29.1$&$27.7$&$43.9$&$35.8$&$37.0$\tabularnewline
RF&$36.3$&$30.0$&$30.7$&$45.8$&$41.2$&$42.1$\tabularnewline
CART&$12.5$&$ 9.9$&$10.0$&$12.8$&$10.0$&$ 9.9$\tabularnewline
1&$12.5$&$12.5$&$12.7$&$ 9.2$&$ 9.2$&$ 9.4$\tabularnewline
0.9&$14.5$&$14.5$&$14.8$&$11.8$&$11.8$&$12.0$\tabularnewline
0.8&$16.2$&$16.2$&$16.5$&$15.0$&$15.0$&$15.3$\tabularnewline
0.7&$16.6$&$16.6$&$16.9$&$18.0$&$18.0$&$18.4$\tabularnewline
0.6&$16.2$&$16.2$&$16.5$&$20.1$&$20.1$&$20.5$\tabularnewline
0.5&$15.5$&$15.5$&$15.8$&$21.1$&$21.1$&$21.5$\tabularnewline
0.4&$15.6$&$15.6$&$16.0$&$19.8$&$19.8$&$20.2$\tabularnewline
0.3&$14.7$&$14.7$&$15.0$&$16.8$&$16.8$&$17.2$\tabularnewline
0.2&$12.7$&$12.7$&$12.9$&$14.1$&$14.1$&$14.4$\tabularnewline
0.1&$10.5$&$10.5$&$10.6$&$11.0$&$11.0$&$11.2$\tabularnewline
  \bottomrule
\end{tabular}
\end{table}

The arithmetic mean survival times under each treatment regime are shown in Figure \ref{fig:results-no-int} for the scenarios without covariate by treatment interaction (patient subgroups with differential treatment response) and in Figure \ref{fig:results-int} for the interaction scenarios--those with covariate by treatment interaction. ``Best'' shows the arithmetic mean survival time for the 2000 test patients when following the best possible dose sequence. The optimal regimes estimated using Q-learning are labelled as ``MARS'', ``RF'', and ``CART'' for Q-learning using MARS, random forest (which in these situations was equivalent to bagging), and regression trees using the CART procedure to estimate the Q-functions, respectively. In Figures \ref{fig:results-no-int} and \ref{fig:results-int}, each of the 100 mean survival times obtained using the optimal regime derived from the 100 different training sets on the test set are displayed as separate points in box plots for the three modeling techniques. Comparison regimes are shown with only a single line because they do not require training and are therefore invariant across training set. Table \ref{tab:rewards} displays the arithmetic mean survival times under each regime, averaged over all of the 100 test set survival times for each of the regimes estimated using each Q-learning technique on each training set.

%latex.default(., file = "", dec = 1, caption = cap, caption.lot = cap_toc,     label = "tab:sd-train-rewards", where = "!htbp", rowname = NULL,     colheads = col_heads, booktabs = T)%
\begin{table}[!htbp]
\caption[Standard deviation of mean survival times across training sets]{Standard deviation of mean survival times across training set replicates for Q-learning models. B is the basic scenario, N is noise scenario, PN is the predictive noise scenario, I is the interaction scenario, I+N is the interaction and noise scenario, and I+PN is the interaction and predictive noise scenario. Each scenario is described in detail in section \ref{sec:simulation}. \label{tab:sd-train-rewards}}
\begin{center}
\begin{tabular}{lrrrrrr}
\toprule
\multicolumn{1}{c}{Regime}&\multicolumn{1}{c}{B}&\multicolumn{1}{c}{N}&\multicolumn{1}{c}{PN}&\multicolumn{1}{c}{I}&\multicolumn{1}{c}{I+N}&\multicolumn{1}{c}{I+PN}\tabularnewline
\midrule
MARS&$9.8$&$8.8$&$8.3$&$9.6$&$7.9$&$9.0$\tabularnewline
RF&$5.2$&$5.2$&$5.8$&$6.0$&$6.4$&$6.5$\tabularnewline
CART&$3.0$&$2.5$&$2.2$&$4.0$&$3.2$&$2.7$\tabularnewline
\bottomrule
\end{tabular}
\end{center}
\end{table}

In the basic (B) scenario, MARS and random forest produce similar mean survival times, about two thirds of the best survival times, with MARS performing slightly better on average. However, as will be repeated throughout scenarios, MARS exhibits more sensitivity to the training set (higher variance) as shown in Figure \ref{fig:results-no-int} and in Table \ref{tab:sd-train-rewards}, which shows standard deviations in mean months of survival across training sets. As is also repeated across scenarios, a single regression tree (labelled ``CART'' throughout) performs very poorly, worse overall than many constant dose regimes. When the 100 noise variables are added in the noise (N) scenario, there is approximately a 10 month decrease in mean survival times for MARS and RF, bringing them to about half of the best possible survival times and about a 2 month decrease for CART. MARS then performs slightly worse than random forest when noise variables are added. Allowing some of the noise variables to shift survival times up or down in the predictive noise (PN) scenario produces results very similar to the noise scenario without predictive noise.

Results from the interaction scenarios, scenarios with the four treatment subgroups created by $X_{1}$ and $X_{2}$, shown in Figure \ref{fig:results-int} and Table \ref{tab:rewards}, were similar to those in the scenarios without interaction, but shifted towards longer survival. Despite the shift upwards, the trend is very similar to the scenarios without interaction. In the interaction only scenario (I), MARS and random forest produce similar mean survival times, a little more than half of those produced by the best possible regime, with MARS showing greater variability across training sets. Addition of noise variables to the interaction scenario (I+N), results in a reduction of around 10 months of survival time for MARS and random forest, bringing them to half or a bit less than half of the best possible survival time. As in the scenarios without interaction, MARS decreases more than random forest when the noise variable are added. Allowing 10 of the noise variables to shift survival up or down by a little in the interaction and predictive noise (I+PN) scenario has little effect on the performance of the estimated regimes. CART produces results very similar to those in the scenarios without interaction.

\begin{figure}[!htbp]
\centering
\includegraphics[width=\textwidth]{figure/var-imps-no-int-1}

\caption[Variable importances for the scenarios without interaction]{Variable importances for the scenarios without interaction. Importances are given as a percentage of the most important variable in each model. Importances from each stage and each training set replicate are shown together in each violin (e.g. each of the 60 importances for tumor mass for each stage for each model are shown together in the three respective violins above M for each scenario). All of the importances for each noise variable in the $Z$ vector are labelled Z, while the variables in the $V$ and $X$ vectors are labelled V and X respectively.}\label{fig:var-imps-no-int}
\end{figure}


\begin{figure}[!htbp]
\centering
\includegraphics[width=\textwidth]{figure/var-imps-int-1}

\caption[Variable importances for interaction scenarios]{Variable importances for the interaction scenarios. Importances are given as a percentage of the most important variable in each model. Importances from each stage and each training set replicate are shown together in each violin (e.g. each of the 60 importances for tumor mass for each stage for each model are shown together in the three respective violins above M for each scenario). All of the importances for each noise variable in the $Z$ vector are labelled Z, while the variables in the $V$ and $X$ vectors are labelled V and X respectively.}\label{fig:var-imps-int}
\end{figure}


\begin{table}[!htbp]
\caption[Mean variable importance across stages and model replicates]{Mean variable importance across stages and model replicates. Importances are given as a percentage of the most important variable in each model. Standard deviations are shown in parentheses. Mean and standard deviation variable importance over all of the importances for each noise variable in the $Z$ vector are labelled $Z$, while the mean and standard deviation importance across all variables in the $V$ and $X$ vectors are labelled $V$ and $X$ respectively. \label{tab:imp}}
\begin{center}
\begin{tabular}{lllllll}
\toprule
\multicolumn{1}{l}{Variable}&\multicolumn{1}{c}{B}&\multicolumn{1}{c}{N}&\multicolumn{1}{c}{PN}&\multicolumn{1}{c}{I}&\multicolumn{1}{c}{I+N}&\multicolumn{1}{c}{I+PN}\tabularnewline
\midrule
{\bfseries MARS}&&&&&&\tabularnewline
~~$M$&97.6 (7.5)&97.2 (8.0)&96.7 (8.2)&98.8 (5.1)&97.7 (6.3)&97.8 (6.2)\tabularnewline
~~$W$&78.6 (9.3)&82.7 (8.1)&83.5 (8.7)&82.2 (6.7)&85.3 (7.3)&86.1 (7.1)\tabularnewline
~~$D$&24.4 (13.3)&36.2 (7.7)&37.1 (8.6)&35.1 (12.8)&45.4 (9.8)&45.4 (8.7)\tabularnewline
~~$X$&&&&33.4 (12.1)&43.7 (13.6)&43.9 (12.6)\tabularnewline
~~$Z$&&5.4 (11.1)&8.0 (13.2)&&5.7 (11.6)&7.8 (13.5)\tabularnewline
~~$V$&&5.3 (10.8)&5.3 (10.9)&&5.9 (11.9)&5.8 (11.8)\tabularnewline
\midrule
{\bfseries RF}&&&&&&\tabularnewline
~~$M$&99.7 (2.0)&99.6 (2.1)&99.5 (2.2)&99.3 (2.3)&99.0 (3.1)&98.9 (3.5)\tabularnewline
~~$W$&79.5 (11.5)&79.0 (12.8)&79.9 (13.2)&85.1 (11.6)&86.0 (10.9)&86.2 (11.5)\tabularnewline
~~$D$&19.4 (7.8)&1.7 (0.8)&1.9 (0.9)&19.8 (7.5)&3.7 (1.8)&3.7 (2.1)\tabularnewline
~~$X$&&&&24.9 (6.8)&6.5 (3.6)&6.5 (3.5)\tabularnewline
~~$Z$&&0.9 (0.5)&0.9 (0.6)&&1.2 (0.6)&1.2 (0.7)\tabularnewline
~~$V$&&0.8 (0.4)&0.8 (0.4)&&1.1 (0.5)&1.1 (0.5)\tabularnewline
\midrule
{\bfseries CART}&&&&&&\tabularnewline
~~$M$&98.8 (3.8)&98.6 (4.2)&98.5 (4.3)&97.3 (6.1)&96.7 (7.8)&96.5 (7.9)\tabularnewline
~~$W$&78.7 (15.3)&77.5 (16.4)&79.4 (16.3)&84.1 (14.2)&83.6 (14.3)&84.4 (14.6)\tabularnewline
~~$D$&5.7 (4.3)&2.0 (3.6)&2.0 (3.7)&8.1 (6.2)&2.3 (3.9)&2.5 (4.2)\tabularnewline
~~$X$&&&&6.9 (5.9)&1.1 (3.0)&1.1 (2.9)\tabularnewline
~~$Z$&&0.0 (0.4)&0.1 (0.5)&&0.0 (0.3)&0.0 (0.4)\tabularnewline
~~$V$&&0.0 (0.4)&0.0 (0.4)&&0.0 (0.4)&0.0 (0.4)\tabularnewline
\bottomrule
\end{tabular}
\end{center}
\end{table}

Variable importances as a percentage of the most important variable for each method, stage, and training set replicate are shown in Figures \ref{fig:var-imps-no-int} and \ref{fig:var-imps-int}. The interaction variables $X_{1}$, $X_{2}$, noise variables with no predictive value, $V_{1}, \ldots, V_{90}$, and noise variables with some predictive value in the scenarios with predictive noise, $Z_{1}, \ldots, Z_{10}$ are shown together as $X$, $V$, and $Z$ respectively. Specifically, the Z label in Figures \ref{fig:var-imps-no-int} and \ref{fig:var-imps-int} shows violin plots of the relative importance for all of the variables in the $Z$ vector for each scenario (and for every stage, so 3000 importances for each violin). Table \ref{tab:imp} shows the mean and standard deviation of the relative importances over the 100 different training models and the three stages, for each variable group vector and each method. For example, the average importance of a $V$ variable for all MARS models (at all stages) in the noise scenario (N) is 5.4, with a standard deviation of 11.1. Mean importances were quite similar between stages.

As shown in Figures \ref{fig:var-imps-no-int} and \ref{fig:var-imps-int} and Table \ref{tab:imp}, $M$ and $W$ are the most important variables across all model types. This aligns well with the higher importance of $M$ and $W$ on survival in the simulated data. Further, $M$ is almost always the most important variable, which agrees with the higher weight that was placed on it in the simulation relative to $W$.

Figures \ref{fig:var-imps-no-int} and \ref{fig:var-imps-int} and Table \ref{tab:imp} also show that this version of MARS is much better than the other modeling techniques at identifying interacting variables and the treatment ($D$) as important. However, it is also much more prone to identify noise variables as important. As with mean survival times, there is higher variance across training sets in the importances MARS assigns to treatment and interacting variables. 

Random forest is best at identifying the noise variables as not important, but also gives a relatively low importance to interacting and treatment variables. A single regression tree (CART) shows a similar trend in importances as the random forest models, but with near zero importance for noise variables and lower importance for dose and interacting ($X$) variables.

% \begin{table}[!htbp]
% \caption[SD of rewards across test sets]{SD of rewards across test sets\label{tab:sd-test-rewards}}
% \centering
% \begin{tabular}{lrrrrrr}
% \toprule
% \multicolumn{1}{c}{Regime}&\multicolumn{1}{c}{B}&\multicolumn{1}{c}{N}&\multicolumn{1}{c}{PN}&\multicolumn{1}{c}{I}&\multicolumn{1}{c}{I+N}&\multicolumn{1}{c}{I+PN}\tabularnewline
% \midrule
% Best&$4.7$&$4.7$&$5.0$&$4.9$&$4.9$&$5.4$\tabularnewline
% MARS&$4.2$&$3.1$&$3.5$&$3.7$&$3.1$&$3.6$\tabularnewline
% RF&$3.5$&$2.9$&$3.7$&$3.6$&$2.8$&$3.1$\tabularnewline
% CART&$0.5$&$0.4$&$0.5$&$0.6$&$0.4$&$0.5$\tabularnewline
% 1&$0.4$&$0.4$&$0.5$&$0.4$&$0.4$&$0.4$\tabularnewline
% 0.9&$0.7$&$0.7$&$0.8$&$0.5$&$0.5$&$0.6$\tabularnewline
% 0.8&$1.2$&$1.2$&$1.3$&$0.8$&$0.8$&$1.0$\tabularnewline
% 0.7&$1.5$&$1.5$&$1.7$&$1.2$&$1.2$&$1.4$\tabularnewline
% 0.6&$2.0$&$2.0$&$2.2$&$1.5$&$1.5$&$1.6$\tabularnewline
% 0.5&$1.8$&$1.8$&$2.0$&$1.8$&$1.8$&$1.9$\tabularnewline
% 0.4&$1.6$&$1.6$&$1.9$&$2.0$&$2.0$&$2.2$\tabularnewline
% 0.3&$1.2$&$1.2$&$1.4$&$1.6$&$1.6$&$1.8$\tabularnewline
% 0.2&$0.9$&$0.9$&$0.9$&$1.0$&$1.0$&$1.1$\tabularnewline
% 0.1&$0.6$&$0.6$&$0.6$&$0.6$&$0.6$&$0.7$\tabularnewline
% \bottomrule
% \end{tabular}
% 
% \end{table}

\section{Discussion} % (fold)
\label{sec:discussion}

% point out that these types of trials are fundamentally exploratory
% you can look for subgroups while also investigating main effect differences between groups

% Main results
Q-learning using random forest (which in these scenarios was equivalent to bagging) and Multivariate Adaptive Regression Splines modified to only interact variables with treatment can increase survival times compared to constant dose regimes by large margins in this simulation. However, Q-learning using single regression trees grown with the CART procedure often performed worse than many constant dose regimes.

% Relation to other literature/previous research
This agrees with the results of \textcite{crt}, but also shows that the more interpretable MARS models can produce comparable results to more complex ``black box'' models. Further, it shows the results in context with the best possible sequence, and gives inklings of the variability in performance due to differences in training data.

% biological rationale/possible explanation/mechanisms
The lack of performance from single regression trees is likely due to the splitting criterion being based on predictive performance and not on a measure of the degree of interaction with the treatment variable. With $SSE$ as the splitting criterion, one can choose to grow a deep, bushy tree that is relatively unbiased but also has high variance (overfits the data), or one can prune to a less variable but more biased tree. In our scenarios, the treatment variable, dose, plays much less of a role in the absolute survival time than tumor mass or toxicity (as shown in the variable importance measures) so it tends to only be split upon further down the tree. To model the effect of dose well, therefore, a large tree is required. However, large trees tend to overfit and hence also don't consistently model the effect of dose well. Attempting to correct this by pruning results in most (or all) of the effects due to dose being pruned off because the cost-complexity criterion use for pruning is also not based on capturing the differential effects of treatment. An analogous explanation applies for the interacting variables.

% strengths and limitations: address limitations but then try to minimize impact
Restricting MARS to only interact covariates with the treatment gave comparable performance to random forest on average, but the survival times produced were more variable, and for some training data were quite low. This most likely due to the restriction on interactions with treatment, which are harder to consistently detect using $SSE$ as the metric for variable addition and removal. This instability could be likely be improved through bagging, though bagging would negate much of the interpretably gained from using MARS.

Using these methods, subgroup identification is difficult. With MARS, although the true interacting variables often have high importance measures, for any given set of training data so may spurious variables. Random forest works well despite low importances for dose and interacting variables, which while a little larger on average than noise variables, would be hard to distinguish in practice.

Due to constraints in computing resources, I could not obtain more precise estimates of the sensitivity of the results to different training sets by simulating more training set replicates. Further, censoring of observations was ignored. If similar methods will be applied to real data with survival outcomes, censoring will need to be incorporated.

% Implications/take home message
The above being said, I showed that statistical learning methods that were designed to maximize predictive performance can be used to personalize treatment regimes with a continuous treatment, increasing mean length of survival in simulated cancer patients.

% Directions for future research
While this approach is more effective than constant doses in this setting, performance can almost certainly be improved by modifying the techniques used to fit Q-functions to use magnitude of interaction as the basis for model building and evaluating performance. This could also greatly increase the interpretability of the Q-functions, and would make subgroup identification much easier. 

Extending this framework to observational data could have a large impact.  For example, through solving some casual inference questions, these techniques could be applied to electronic medical record data for people with chronic diseases. This could lead to a much better understanding of how to to tailor treatment sequences to a patient's individual characteristics and their changing disease.

% section discussion (end)

\printbibliography

\end{document}
