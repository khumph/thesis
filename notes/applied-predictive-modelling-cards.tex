\documentclass[10pt]{book} 
\usepackage{amssymb,amsmath,amsfonts,mathrsfs} 
\usepackage[paperwidth=5in, paperheight=100in, textheight = 99in]{geometry} 
\pagestyle{empty}

% makes table of contents and such hyperlinks
\usepackage{hyperref}

% > < print corectly, accented words hyphenate
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc} 

% English language/hyphenation
\usepackage[english]{babel} 

% Math packages
\usepackage{amsmath, amsfonts, amsthm, amssymb} 

% lots of math mode conveniences
\usepackage{commath} 

% bold math
\usepackage{bm}

% Removes all indentation from paragraphs
\setlength{\parindent}{0pt}
% add spaces when returning
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\newcommand{\E}{\operatorname{E}}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\Cov}{\operatorname{Cov}}
\newcommand{\bias}{\operatorname{bias}}
\newcommand{\MSE}{\operatorname{MSE}}
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

\newcommand{\h}{\hrulefill}

\begin{document}
\tableofcontents

\chapter{An Introduction to Feature Selection} % (fold)
\label{chap:an_introduction_to_feature_selection}

\section{Approaches for Reducing the Number of predictors} % (fold)
\label{sec:approaches_for_reducing_the_number_of_predictors}

What are the two main categories for reducing the number of predictors (apart from models with built-in feature selection)?

\begin{enumerate}
  \item Wrapper methods
  \item Filter methods
\end{enumerate}

\hrulefill

What are wrapper methods?

Category of approaches to doing feature selection.

Essentially search algorithms that treat predictors as inputs and use model performance as output to optimize.

(Use procedures that add and/or remove predictors to find optimal combinations that maximize model performance.)

\hrulefill

What are filter methods?

Category of approaches to doing feature selection.

Evaluate the relevance of the predictors outside of model, only include predictors in model that fulfill some criterion. 

E.g. in a classification problem, each predictor could be individually evaluated to check for a plausible relationship with observed classes.

\hrulefill

What are the strengths and weaknesses of filter methods?

Strengths:
\begin{enumerate}
  \item Usually more computationally efficient than wrapper methods
\end{enumerate}

Weaknesses:
\begin{enumerate}
  \item Selection criterion not directly related to model effectiveness
  \item most evaluate each predictor separately, redundant variables may be retained
\end{enumerate}

\hrulefill

What are the strengths and weaknesses of wrapper methods?

Strengths of filter methods:
\begin{enumerate}
  \item usually more computationally efficient
\end{enumerate}

Weaknesses of filter methods:
\begin{enumerate}
  \item Selection criterion not directly related to model effectiveness
  \item most evaluate each predictor separately, redundant variables may be retained
\end{enumerate}



% section approaches_for_reducing_the_number_of_predictors (end)

% chapter an_introduction_to_feature_selection (end)

\end{document}